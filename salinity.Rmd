---
title: "Salinity"
author: "Rashnil"
date: "21 November 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Salinity Data

sal <- read.table(file.choose(),header = FALSE)

```{r longley}
sal <- read.table(file.choose(),header = FALSE);
names(sal) <-c("obs","sal","lagsal","fflow","period","year");
summary(sal)
n<-length(sal$obs)
```

#Build the initial model with all the variables
```{r}
model_full<-lm(sal~lagsal+fflow+period+year,data = sal);
summary(model_full);
```


# Build full model with all the variables and the initial model with no variable

```{r}
model_0 <- lm(sal~1,data = sal);
model_full<-lm(sal~lagsal+fflow+period+year,data = sal)
```

# Run the stepwise forward selection process to identify the best model
```{r}
sal.step<- step(model_0,scope = list(lower=model_0,upper=model_full),direction = "forward");

summary(sal.step)
```

Above model selection leads to model with legsal,fflow,year

#Check whether Transformation is required using BOX COX
```{r}
library("MASS")
boxcox(sal.step,lambda = seq(-.5,3,0.1),interp = TRUE)
bc <- boxcox(sal.step,lambda = seq(-.5,3,0.1),interp = TRUE)
bc$x[which.max(bc$y)]
```

The possible transformation candidates from this can be 0.5(Square root) and 1(No transformation)

# Testing for square root and no transformation

Square Root
```{r}
mean<-1;
for(i in 1:n){mean <- mean*sal$sal[i]};
lambda <- 0.5;p<-3;
h_sal <- (mean^(1-lambda))*((sal$sal^lambda-1)/lambda);
Sq_rt_sse <- (summary(lm(h_sal ~ sal$lagsal+sal$fflow+sal$year))$sigma)^2/(n-p);
AIC_sqrt<-n*log(Sq_rt_sse/n) +2*p
BIC_sqrt<-n*log(Sq_rt_sse/n) +p*log(n)
print(AIC_sqrt)
print(AIC_sqrt)

```

No Transformation lambda =1
```{r}
mean<-1;
for(i in 1:n){mean <- mean*sal$sal[i]};
lambda <- 1;p<-3;
no_trans_sse <- (summary(lm(sal$sal ~ sal$lagsal+sal$fflow+sal$year))$sigma)^2/(n-p);
AIC_no_trans<-n*log(no_trans_sse/n) +2*p
BIC_no_trans<-n*log(no_trans_sse/n) +p*log(n)
print(AIC_no_trans)
print(BIC_no_trans)

```

This gives lowet AIC and BIC with No Transformation. Hence, we can go ahead with our model of no transformation.

# Building model with No Transformation

```{r}
final_model <-lm(sal~lagsal+fflow+year, data = sal);
summary(final_model)

```

# Diagnostics for influential values and outliers
```{r}
sigma<-summary(final_model)$sigma
inf<- lm.influence(final_model)
shapiro.test(final_model$residual)

```

Shapiro Wilk test gives values on the higher side. Therefore, we need to test further with plots to get the influential observations

```{r}
par(mfrow=c(1,3))

#Internal Studentized Residuals
Internally.Studentized.Residual<-final_model$residuals/
(sigma*sqrt(1-inf$hat))
plot(Internally.Studentized.Residual);title("Internally Standardized Residual")
abline(h=c(-2,2),lty="dotted")
for(i in 1:n){
if(abs(Internally.Studentized.Residual[i])> 2)text(i+1,Internally.Studentized.Residual[i],i,cex=0.6)}

#External Studentized Residuals
Externally.Studentized.Residual<-final_model$residuals*
sqrt((n-p-1)/((1-inf$hat)*(n-p)*sigma^2
- (final_model$residuals)^2))
plot(Externally.Studentized.Residual);title("Externally Studentized Residual")
abline(h=c(-2,2),lty="dotted")
for(i in 1:n){
if(abs(Externally.Studentized.Residual[i])> 2)text(i+1,Externally.Studentized.Residual[i],i,cex=0.6)}

#qq plot
qqnorm(Externally.Studentized.Residual);abline(c(0,0),c(1,1))

```

From these plots observation 16 and 9 seems outliers. Testing Leverage, Cook's D, DFFITS

```{r}
par(mfrow=c(2,2))

plot(inf$hat);
title("leverage plot")
abline(h=2*p/n,lty=3) ### high leverage points
leverage<-c(inf$hat>2*p/n)
for(i in 1:n){ if(leverage[i]==T)text(i+1,inf$hat[i],i,cex=0.6)}

DFFITS <- Externally.Studentized.Residual*sqrt(inf$hat/(1-inf$hat))
plot(DFFITS);abline(h=2*sqrt(p/n),lty=2);abline(h=-2*sqrt(p/n),lty=2);title("DFFITS")
DF.detected <- c(abs(DFFITS)> 2*sqrt(p/n))
for(i in 1:n){ if(DF.detected[i]==T)text(i+1,DFFITS[i],i,cex=0.6)}

#Cooks D
plot(final_model, which=4)

first <- ((n-p-1) / (n-p))+ Externally.Studentized.Residual^2/(n-p)
COVRATIO <- first^(-p) /(1-inf$hat)
plot(COVRATIO);abline(h=3*p/n+1,lty=2);
abline(h=-3*p/n+1,lty=2);title("COVRATIO")
CR.detected <- c(abs(COVRATIO-1)>3*p/n)
for(i in 1:n){ if(CR.detected[i]==T)text(i+1,COVRATIO[i],i,cex=0.6)}

```

From all these plots, clearly observation 16 seems to be an influential observation. Therefore, we can remove obs 16 from data and check normality

## Removing Obervation 16 and test 

```{r}
sal_new<-subset(sal,obs !=16)
new_model <-lm(sal~lagsal+fflow+year, data = sal_new);
summary(new_model)
```

It can be seen from this model that p-value of year does not seems significant.
Therefore, we can remove year and for a new model with lagsal and fflow

```{r}
new_model_final <-lm(sal~lagsal+fflow, data = sal_new);
summary(new_model_final)
```

This looks to be the optimal model we can get. The R square value is able to explain the maximum variability in the data of around 87%

